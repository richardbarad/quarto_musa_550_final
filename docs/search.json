[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MUSA 5500 Final Project",
    "section": "",
    "text": "This website was built to showcase my final project for MUSA 5500 - Geospatial Analysis in Python.\nMy project focuses on analyzing vulnerability to flooding in Philadelphia. The city of Philadelphia is built between two rivers, the Schuylkill, and the Delaware River, and many neighborhoods in the city face a high vulnerability to flooding. This vulnerability is only going to increase due to climate change. Philadelphia’s policies and local development practices have not always followed best practices when it comes to flood plain management. Hundreds of city residents were left stranded at the Apex Apartment building on Venice Island in Manayunk when the Schuykill river flooded its banks after the remnants of Hurricane Ida passed through the Philadelphia metro area1. New construction is also taking place in the Navy Yard area, and the city recently allowed the construction of residential units in the Navy Yard despite the Navy Yard being one of the most flood prone neighborhoods in the city2. The Navy Yard plans to include steps to try to mitigate flooding, but many including Josh Lippert the city’s former flood plain manager think the measures being taken are inadequate2. Residents of Clearview and Eastwick, blue collar neighborhoods in Southwest Philadelphia, are also experiencing a rising risk of vulnerability to flooding due to sea level rise and more frequent extreme weather events3.\nMy project seeks to better understand who is vulnerable to flooding in Philadelphia. I examine the demographic breakdown of populations living in census blocks located near the flood hazard zone and see how the population living near the flood plain has changed over time. I attempted to determine if the population of ethnic minority groups living in the floodplain has increased. Additionally, I look to see if the demographic breakdown and trends vary across different geographic sections of the city.\nI also examine the amount of infrastructure located within the floodplain. In my analysis I count the number of infrastructure amenities located within the floodplain. Examples of infrastructure amenities include schools and restaurants. I also count the total number of buildings located within the floodplain, and look at the breakdown by section of the city and if the buildings are located in the 100-year or 500-year floodplain. Results are presented by census block group and by planning district.\n1 Adam Green and Bernard Brown, In Harm’s Way, GridPhilly, September 2023. https://gridphilly.com/blog-home/2023/09/04/reckless-developments-put-residents-in-floods-path/\n2 Sophia Schmidt, WHYY, Philadelphia, Thousands of people could live at the flood-prone Navy Yard. Will they be safe? July 19th, 2022 https://whyy.org/articles/navy-yard-flood-prone-development/\n3 John Hurdle, YaleEnvironment 360, Yale School of Environment, As Waters Rise, a Community Must Decide: Do We Stay or Go? https://e360.yale.edu/features/chronic-flooding-eastwick-philadelphia"
  },
  {
    "objectID": "index.html#about-my-project",
    "href": "index.html#about-my-project",
    "title": "MUSA 5500 Final Project",
    "section": "",
    "text": "This website was built to showcase my final project for MUSA 5500 - Geospatial Analysis in Python.\nMy project focuses on analyzing vulnerability to flooding in Philadelphia. The city of Philadelphia is built between two rivers, the Schuylkill, and the Delaware River, and many neighborhoods in the city face a high vulnerability to flooding. This vulnerability is only going to increase due to climate change. Philadelphia’s policies and local development practices have not always followed best practices when it comes to flood plain management. Hundreds of city residents were left stranded at the Apex Apartment building on Venice Island in Manayunk when the Schuykill river flooded its banks after the remnants of Hurricane Ida passed through the Philadelphia metro area1. New construction is also taking place in the Navy Yard area, and the city recently allowed the construction of residential units in the Navy Yard despite the Navy Yard being one of the most flood prone neighborhoods in the city2. The Navy Yard plans to include steps to try to mitigate flooding, but many including Josh Lippert the city’s former flood plain manager think the measures being taken are inadequate2. Residents of Clearview and Eastwick, blue collar neighborhoods in Southwest Philadelphia, are also experiencing a rising risk of vulnerability to flooding due to sea level rise and more frequent extreme weather events3.\nMy project seeks to better understand who is vulnerable to flooding in Philadelphia. I examine the demographic breakdown of populations living in census blocks located near the flood hazard zone and see how the population living near the flood plain has changed over time. I attempted to determine if the population of ethnic minority groups living in the floodplain has increased. Additionally, I look to see if the demographic breakdown and trends vary across different geographic sections of the city.\nI also examine the amount of infrastructure located within the floodplain. In my analysis I count the number of infrastructure amenities located within the floodplain. Examples of infrastructure amenities include schools and restaurants. I also count the total number of buildings located within the floodplain, and look at the breakdown by section of the city and if the buildings are located in the 100-year or 500-year floodplain. Results are presented by census block group and by planning district.\n1 Adam Green and Bernard Brown, In Harm’s Way, GridPhilly, September 2023. https://gridphilly.com/blog-home/2023/09/04/reckless-developments-put-residents-in-floods-path/\n2 Sophia Schmidt, WHYY, Philadelphia, Thousands of people could live at the flood-prone Navy Yard. Will they be safe? July 19th, 2022 https://whyy.org/articles/navy-yard-flood-prone-development/\n3 John Hurdle, YaleEnvironment 360, Yale School of Environment, As Waters Rise, a Community Must Decide: Do We Stay or Go? https://e360.yale.edu/features/chronic-flooding-eastwick-philadelphia"
  },
  {
    "objectID": "analysis/3-building-analysis.html",
    "href": "analysis/3-building-analysis.html",
    "title": "Building Analysis",
    "section": "",
    "text": "This analysis looks at the number of buildings located within the flood hazard area in the city of Philadelphia. Building data is downloaded from Open Street Maps. I determine the planning district and census block each building is located in and present summary maps showing the number of buildings in the flood hazard zone in each planning district and census block.\n\nImport Packages\nI import the packages I will use for this analysis. I used osmnx to download data from Open Street Maps. Pandas and geopandas are used to manipulate and transform my data. Altair and matplotlib are used to create visualizations. Pygris is used for downloading the census block group boundaries for Philadelphia.\n\n\nCode\nimport pandas as pd\nimport osmnx as ox\nfrom matplotlib import pyplot as plt\nimport geopandas as gpd\nimport altair as alt\nimport pygris\n\n\n\n\nCode\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\nGet Data on Flood Plains\nI get the flood hazard boundary data from the city’s open data portal. The 100 year and 500 year flood plain are included as seperate layers. I perform some cleaning operations to both layers and then concatenate them together using the concat function in pandas.\n\n\nCode\nflood_plain_100_year = gpd.read_file('https://opendata.arcgis.com/datasets/1d6d353ab50b4884b586c05ee2a661db_0.geojson').to_crs(6565)\nflood_plain_500_year = gpd.read_file('https://opendata.arcgis.com/datasets/1e6f6315225544c88549478d25cc5181_0.geojson').to_crs(6565)\n\n\n\n\nCode\nflood_plain_100_year.loc[flood_plain_100_year['FLOODWAY'] == 'FLOODWAY', ['ZONE']] = 'FLOODWAY'\nflood_plain_100_year = flood_plain_100_year[['geometry','ZONE']].fillna('100 YEAR')\nflood_plain_500_year['ZONE'] = '500 YEAR'\nflood_plain_500_year = flood_plain_500_year[['geometry','ZONE']]\nflood_plain = pd.concat([flood_plain_100_year,flood_plain_500_year])\n\n\n\n\nCode\nplanning_districts = gpd.read_file('https://opendata.arcgis.com/datasets/0960ea0f38f44146bb562f2b212075aa_0.geojson').to_crs(6565)\n\n\n\n\nGet Building Data\nI carry out an analysis to determine the number of buildings that are located within the flood hazard zone. The building data is downloaded from open street maps using osmnx. The building data from OSM includes both polygons and points - in order to ensure that all the features in my buildings dataset are points I take the centroid of the building features.\nI then carry out a spatial join between the buildings and the boundaries of the flood hazard zone and create a new dataframe that only includes buildings whoose centroid is located in the flood hazard zone. I also use additional spatial joins to determine what planning district each building that is vulnerable to flooding is located in and the census block each building is located in.\n\n\nCode\nbuildings = ox.features_from_place(\"Philadelphia, PA\", {\"building\": True})\n\n\n\n\nCode\nbuildings = buildings.to_crs(6565).reset_index()\nbuildings['geometry'] = buildings.geometry.centroid\n\n\n\n\nCode\nphilly_2020_block_groups = pygris.block_groups(state='42', county='101', year=2020).to_crs(6565)\n\n\n\n\nCode\nbuildings_f = buildings.sjoin(flood_plain,how='inner',predicate='within')\nbuildings_f.drop('index_right',axis=1,inplace=True)\nbuildings_f = buildings_f.sjoin(planning_districts[['DIST_NAME','geometry']],how='inner',predicate='within')\nbuildings_f.drop('index_right',axis=1,inplace=True)\nbuildings_f = buildings_f.sjoin(philly_2020_block_groups[['GEOID','geometry']],how='inner',predicate='within')\n\n\n\n\nAnalysis by Planning District\nThe code below counts the number of buildings in each planning district that are located within the flood hazard zone.\n\n\nCode\npd_count = buildings_f.groupby('DIST_NAME')[['osmid']].count()\npd_count.rename({'osmid':'count'},inplace=True,axis=1)\nplanning_districts = planning_districts[['DIST_NAME','geometry']].merge(pd_count,on='DIST_NAME',how='left')\n\n\nThe map below is created using matplotlib and shows the number of buildings in the flood zone by planning district. The planning district with the larger number of buildings in the flood zone is the Southwest planning zone.\n\n\nCode\nfig, ax = plt.subplots()\n\nplanning_districts.plot(ax=ax,column=\"count\",legend=True,cmap='OrRd',edgecolor='black')\n\nax.set_axis_off()\nax.set_aspect(\"equal\")\n\nplt.title('# of Buildings in the Flood Hazard Zone by Planning District')\n\n\nText(0.5, 1.0, '# of Buildings in the Flood Hazard Zone by Planning District')\n\n\n\n\n\nThe chart below is created using altair and provides another way of visulizing the number of buildings located within the flood hazard zone. The color in the chart indicates the number of buildings in the floodway, in the 100 year flood plain, and the number in the 500 year floodplain. We can again observe that the largest number of buildings in the flood hazard zone are located in the Lower Southwest Planning District.\n\n\nCode\npd_count = buildings_f.groupby(['DIST_NAME','ZONE'],as_index=False)[['osmid']].count()\npd_count.rename({'osmid':'count'},inplace=True,axis=1)\n\ndomain1 = ['FLOODWAY','100 YEAR','500 YEAR']\nrange2 = ['red','blue','lightblue']\n\nalt.Chart(pd_count).mark_bar().encode(\n    alt.X('DIST_NAME').title('Planning District'),\n    alt.Y('count').title('Building Count'),\n    alt.Color('ZONE').scale(domain=domain1, range=range2),\n    tooltip=['DIST_NAME','count','ZONE']\n).properties(\n    width=550,\n    height=300,\n    title='Number of Buildings Located in Flood Hazard Zone by Planning District'\n)\n\n\n\n\n\n\n\n\n\n\nAnalysis by Census Block Group\nThe analysis below examine the number of buildings in each census block that are located within the flood hazard zone. Census blocks that contain a large number of buildings in the flood hazard zone are located in southwest Philadelphia, in Center City along the Schuylkill river, and near the Delaware river in Fishtown.\n\n\nCode\npd_count = buildings_f.groupby('GEOID')[['osmid']].count()\npd_count.rename({'osmid':'count'},inplace=True,axis=1)\nblock_groups = philly_2020_block_groups[['GEOID','geometry']].merge(pd_count,on='GEOID',how='left')\n\n\n\n\nCode\nfig, ax = plt.subplots()\n\nblock_groups.plot(ax=ax,edgecolor='none',facecolor='#ededed')\nblock_groups.plot(ax=ax,column=\"count\",legend=True,cmap='OrRd',edgecolor='lightgrey',linewidth=0.5)\n\nax.set_axis_off()\nax.set_aspect(\"equal\")\n\nplt.title('# of Buildings in the Flood Hazard Zone by Block Group')\n\n\nText(0.5, 1.0, '# of Buildings in the Flood Hazard Zone by Block Group')"
  },
  {
    "objectID": "analysis/1-race-analysis.html",
    "href": "analysis/1-race-analysis.html",
    "title": "Census Analysis",
    "section": "",
    "text": "This analysis examines the estimated population living in census block groups in Philadelphia that overlap flood prone areas. The analysis only examines costal and riverine flooding and does not capture infrastructure flooding or sea level rise from climate change. Flood prone areas are defined as areas within FEMA’s 500-year flood plain. The population data used comes from the decennial and 5 year American community survey (ACS) datasets which are maintained by the U.S Census Bureau. This analysis breaks the population down by race and by geographic section of the city. The boundaries used to define geographic areas of the city come from the Philadelphia Open Data Portal."
  },
  {
    "objectID": "analysis/1-race-analysis.html#get-data",
    "href": "analysis/1-race-analysis.html#get-data",
    "title": "Census Analysis",
    "section": "Get Data",
    "text": "Get Data\nThe first step in my analysis is to get my census data. I choose to use five-year ACS data from 2021, 2018 and 2015 and decennial census from 2000 and 2010. The data I import includes the total population, and the population breakdown by race for all census tracts in Philadelphia. The census data is downloaded using cenpy. Because this analysis uses decennial datasets and the acs datasets it was necessary to determine the appropriate variables in both the ACS and the deccenial data prior to carrying out my analysis. I did this using a combination of cenpy functions and Social Explorer.\n\n\nCode\n#Make API Connections to different ACS datasets\nacs2021 = cenpy.remote.APIConnection(\"ACSDT5Y2021\")\nacs2018 = cenpy.remote.APIConnection(\"ACSDT5Y2018\")\nacs2015 = cenpy.remote.APIConnection(\"ACSDT5Y2015\")\ndec2010 = cenpy.remote.APIConnection(\"DECENNIALSF12010\")\ndec2000 = cenpy.remote.APIConnection(\"DECENNIALSF12000\")\n\n\n\n\nCode\nvariables_acs = ['NAME',\n               'B03002_001E',#Total Pop\n              'B03002_003E', #White Pop\n              'B03002_004E', #Black Pop\n              'B03002_005E', #American Indian Pop\n              'B03002_006E', #Asian Pop\n              'B03002_007E', #Hawian Native Pop\n              'B03002_008E', #Other Race\n              'B03002_009E',#Some other race\n                'B03002_012E' ] #Hispanic\n\nvariables_dec2010 = ['NAME',\n                    'P005001', #Total Pop\n                    'P005003', #White Pop\n                    'P005004', #Black Pop\n                    'P005005',#American Indian Pop\n                    'P005006', #Asian Pop\n                    'P005007', #Native Hawian,\n                    'P005008', #Some other race\n                    'P005009',#Two or more races\n                    'P005010']#Hispanic\n\nvariables_dec2000 = ['NAME',\n                     'P004001', #Total Pop\n                     'P004002', #Hispanic or Latino\n                     'P004005', #White\n                     'P004006', #Black\n                     'P004007', #American Indian Pop\n                     'P004008', #Asian\n                     'P004009', #Native Hawian\n                     'P004010', #Some other race\n                     'P004011'] #Two or more race\n                     \n\n\n\n\nCode\ndf_acs2021 = acs2021.query(\n    cols=variables_acs,\n    geo_unit=\"block group:*\",\n    geo_filter={\"state\": \"42\", \"county\": \"101\", \"tract\": \"*\"},\n)\n\ndf_acs2018 = acs2018.query(\n    cols=variables_acs,\n    geo_unit=\"block group:*\",\n    geo_filter={\"state\": \"42\", \"county\": \"101\", \"tract\": \"*\"},\n)\n\ndf_acs2015 = acs2015.query(\n    cols=variables_acs,\n    geo_unit=\"block group:*\",\n    geo_filter={\"state\": \"42\", \"county\": \"101\", \"tract\": \"*\"},\n)\n\ndf_census2010 = dec2010.query(\n    cols=variables_dec2010,\n    geo_unit=\"block group:*\",\n    geo_filter={\"state\": \"42\", \"county\": \"101\", \"tract\": \"*\"},\n)\n\ndf_census2000= dec2000.query(\n    cols=variables_dec2000,\n    geo_unit=\"block group:*\",\n    geo_filter={\"state\": \"42\", \"county\": \"101\", \"tract\": \"*\"},\n)"
  },
  {
    "objectID": "analysis/1-race-analysis.html#clean-census-data",
    "href": "analysis/1-race-analysis.html#clean-census-data",
    "title": "Census Analysis",
    "section": "Clean Census Data",
    "text": "Clean Census Data\nMy next step is to clean the census data. Because cenpy returns population data as characters is was first necessary to convert all the numeric columns to floats. After converting the data to floats, I rename my columns of interest so that they are easier for me to remember and easier for readers to understand. Additionally, I group together the population which is not White, Asian, Black, or Hispanic into an ‘Other_Pop’ group. The other pop group includes Native Americans, Native Hawaiians, other races, and residents who identified as multi-racial.\nIn order to streamline my data cleaning procedure I created functions which include the data cleaning steps. The clean_acs function is used to clean the acs data, while the clean_dec2010 function is used to clean the 2010 decennial data, and the clean_dec2000 function is used to clean the 2000 decennial data.\n\n\nCode\ndef clean_acs(df,year):\n    for variable in variables_acs:\n        if variable != \"NAME\":\n            df[variable] = df[variable].astype(float)\n    df.rename({'B03002_001E':'Total_Pop','B03002_003E':'White_Pop','B03002_004E':'Black_Pop','B03002_012E':'Hispanic_Pop','B03002_006E':'Asian_Pop'},inplace=True,axis=1)\n    df['year'] = year\n    other_pop_list = ['B03002_005E','B03002_007E','B03002_008E','B03002_009E']\n    df['Other_Pop'] = df[other_pop_list].sum(axis=1)\n    df.drop(other_pop_list,inplace=True,axis=1)\n    return df\n\ndef clean_dec2010(df,year):\n    for variable in variables_dec2010:\n        if variable != \"NAME\":\n            df[variable] = df[variable].astype(float)\n    df.rename({'P005001':'Total_Pop','P005003':'White_Pop','P005004':'Black_Pop','P005010':'Hispanic_Pop','P005006':'Asian_Pop'},inplace=True,axis=1)\n    df['year'] = year\n    other_pop_list = ['P005005','P005007','P005008','P005009']\n    df['Other_Pop'] = df[other_pop_list].sum(axis=1)\n    df.drop(other_pop_list,inplace=True,axis=1)\n    return df\n\ndef clean_dec2000(df,year):\n    for variable in variables_dec2000:\n        if variable != \"NAME\":\n            df[variable] = df[variable].astype(float)\n    df.rename({'P004001':'Total_Pop','P004005':'White_Pop','P004006':'Black_Pop','P004002':'Hispanic_Pop','P004008':'Asian_Pop'},inplace=True,axis=1)\n    df['year'] = year\n    other_pop_list = ['P004007','P004009','P004010','P004011']\n    df['Other_Pop'] = df[other_pop_list].sum(axis=1)\n    df.drop(other_pop_list,inplace=True,axis=1)\n    return df\n\n\n\n\nCode\ndf_acs2021 = clean_acs(df_acs2021,2021)\ndf_acs2018 = clean_acs(df_acs2018,2018)\ndf_acs2015 = clean_acs(df_acs2015,2015)\n\n\n\n\nCode\ndf_census2010 = clean_dec2010(df_census2010,2010)\ndf_census2000 = clean_dec2000(df_census2000,2000)"
  },
  {
    "objectID": "analysis/1-race-analysis.html#get-block-group-boundaries-and-join-to-census-data",
    "href": "analysis/1-race-analysis.html#get-block-group-boundaries-and-join-to-census-data",
    "title": "Census Analysis",
    "section": "Get Block Group Boundaries and Join to Census Data",
    "text": "Get Block Group Boundaries and Join to Census Data\nThe next step is to download the block groups which are needed to map my data. The ACS data from 2021 uses the 2020 block groups, while the ACS data for 2018, 2015 and the 2010 decennial census data utilize the 2010 census block groups. The 2000 decennial census data utilizes the 2000 census blocks.\nThe 2020 census block group boundaries are obtained using pygris. Unfortunately, I was not able to download the 2010 and 2020 census block group boundaries using pygris. Thus, I obtained the 2010 block group boundaries from open data philly. The 2000 census boundaries were downloaded from the census.gov and I saved the boundaries as a shapefile on my computer and read the shapefile into python using geopandas.\n\n\nCode\nphilly_code='101'\nstate_code='42'\n\nphilly_2020_block_groups = pygris.block_groups(\n    state=state_code, county=philly_code, year=2020\n).to_crs(6565)\n\n#Read in 2010 block groups from Open Data Philly because I could not get pygris to work with 2010 as year\nphilly_2010_block_groups = gpd.read_file('https://opendata.arcgis.com/datasets/2f982bada233478ea0100528227febce_0.geojson').to_crs(6565)\n\nphilly_2010_block_groups.rename({'GEOID10':'GEOID'},inplace=True,axis=1)\n\n#Downloaded 2000 block groups from census.gov - could not get pygris to work and 2000 not available on Open Data Philly.\n\nphilly_2000_block_groups = gpd.read_file('./data/Philly_2000_census.shp').drop('NAME',axis=1).to_crs(6565)\n\n\nAfter obtaining all the necessary census boundaries I join each of the census datasets to the appropriate geospatial boundaries using the pandas merge function.\n\n\nCode\ndf_acs2021_g = philly_2020_block_groups.merge(\n    df_acs2021,\n    left_on=[\"STATEFP\", \"COUNTYFP\", \"TRACTCE\", \"BLKGRPCE\"],\n    right_on=[\"state\", \"county\", \"tract\", \"block group\"],\n)\n\ndf_acs2018_g = philly_2010_block_groups.merge(\n    df_acs2018,\n    left_on=[\"STATEFP10\", \"COUNTYFP10\", \"TRACTCE10\", \"BLKGRPCE10\"],\n    right_on=[\"state\", \"county\", \"tract\", \"block group\"],\n)\n\ndf_acs2015_g = philly_2010_block_groups.merge(\n    df_acs2015,\n    left_on=[\"STATEFP10\", \"COUNTYFP10\", \"TRACTCE10\", \"BLKGRPCE10\"],\n    right_on=[\"state\", \"county\", \"tract\", \"block group\"],\n)\n\ndf_census2010_g = philly_2010_block_groups.merge(\n    df_census2010,\n    left_on=[\"STATEFP10\", \"COUNTYFP10\", \"TRACTCE10\", \"BLKGRPCE10\"],\n    right_on=[\"state\", \"county\", \"tract\", \"block group\"],\n)\n\ndf_census2000_g = philly_2000_block_groups.merge(\n    df_census2000,\n    left_on=[\"STATE\", \"COUNTY\", \"TRACT\", \"BLKGROUP\"],\n    right_on=[\"state\", \"county\", \"tract\", \"block group\"],\n)"
  },
  {
    "objectID": "analysis/1-race-analysis.html#merge-data-for-all-years",
    "href": "analysis/1-race-analysis.html#merge-data-for-all-years",
    "title": "Census Analysis",
    "section": "Merge data for all years",
    "text": "Merge data for all years\nNext, I trim the collums included in each of the census datasets so that they all include the same columns. This is necessary in order to merge all the datasets into one geodataframe. After trimming each dataset I use the pandas concatenate function to merge together the data for all five years. The merged geodataframe also includes the geometry column to facilitate geospatial analysis and mapping.\n\n\nCode\n\nkeep_cols = ['NAME','state','county','block group','tract','year','Total_Pop','White_Pop','Black_Pop','Asian_Pop','Hispanic_Pop','Other_Pop','geometry']\n\ndf_acs2021_g = df_acs2021_g[keep_cols]\ndf_acs2018_g = df_acs2018_g[keep_cols]\ndf_acs2015_g = df_acs2015_g[keep_cols]\ndf_census2010_g = df_census2010_g[keep_cols]\ndf_census2000_g = df_census2000_g[keep_cols]\n\n\n\n\nCode\nall_years = pd.concat([df_acs2021_g,df_acs2018_g,df_acs2015_g,df_census2010_g,df_census2000_g]).reset_index(drop=True)"
  },
  {
    "objectID": "analysis/1-race-analysis.html#covert-to-centroid",
    "href": "analysis/1-race-analysis.html#covert-to-centroid",
    "title": "Census Analysis",
    "section": "Covert to centroid",
    "text": "Covert to centroid\nNext, I convert the merged census block group dataset from polygons to point. The centroid of each census block group is used as the point geometry. This step is necessary because I use the centroid to determine if a census block group is adjacent to the floodplain.\n\n\nCode\n# copy GeoDataFrame\nall_years['infloodplain'] = False\nall_years_points = all_years.copy()\n# change geometry \nall_years_points['geometry'] = all_years_points['geometry'].centroid"
  },
  {
    "objectID": "analysis/1-race-analysis.html#identify-census-blocks-adjacent-to-the-floodplain",
    "href": "analysis/1-race-analysis.html#identify-census-blocks-adjacent-to-the-floodplain",
    "title": "Census Analysis",
    "section": "Identify Census Blocks Adjacent to the Floodplain",
    "text": "Identify Census Blocks Adjacent to the Floodplain\nThe next step is to identify which census block groups that are adjacent to the floodplain. I use a spatial join to join the census block group centroids to the buffered floodplain and identify which census block groups are located within the buffered floodplain. I add a new column called “infloodplain” to the merged census block group geodataframe and set this equal to True for census tracts that have a centroid overlapping the buffered floodplain.\nOne challenege with working with different census block group layers is the census block group boundaries have changed over time. In order to account for this, I manually assign multiple census block groups as located near the floodplain to ensure that our map of areas located near the floodplain is roughly the same across all five years of analysis. It is not possible to get perfect allignment across all census block group datasets due to some larger shifts in the census block group boundaries. This is espically true in the shift from the 2000 census block group boundaries to the 2010 census block group boundaries. The maps in next section will show what the mapping of census block groups that are adjacent to the floodplain looks like for each set of census boundaries.\n\n\nCode\n#Determine which census tract centroids overlap the flood plain buffer\ninfloodplain = all_years_points.sjoin(buffer2,how='inner').index\n\nall_years.iloc[[infloodplain],[13]] = True\n\n\n\n\nCode\n\"\"\"\nThere were a much larger number of census blocks in 2000 - \nin order to insure comparability between years I had to reassign several census blocks to be in the flood plain manually \n(or not in the flood plain)\n\"\"\"\n\ndef set_inflood_true(df,year,tract,block):\n    filt = (df['year'] == year) & (df['tract'] == tract) & (df['block group'] == block)\n    df.loc[filt,'infloodplain'] = True\n    \ndef set_inflood_false(df,year,tract,block):\n    filt = (df['year'] == year) & (df['tract'] == tract) & (df['block group'] == block)\n    df.loc[filt,'infloodplain'] = False\n    \nset_inflood_true(all_years,2000,'0328','1')\nset_inflood_true(all_years,2000,'0351','1')\nset_inflood_true(all_years,2000,'0068','9')\nset_inflood_true(all_years,2000,'0035','1')\nset_inflood_true(all_years,2000,'0034','1')\nset_inflood_true(all_years,2000,'0124','1')\nset_inflood_true(all_years,2000,'0150','9')\nset_inflood_true(all_years,2000,'0034','2')\nset_inflood_true(all_years,2000,'0089','2')\nset_inflood_true(all_years,2000,'0089','3')\nset_inflood_true(all_years,2000,'0223','2')\nset_inflood_true(all_years,2000,'0209','3')\nset_inflood_true(all_years,2000,'0033','1')\nset_inflood_true(all_years,2000,'0013','5')\nset_inflood_true(all_years,2000,'0143','3')\nset_inflood_true(all_years,2000,'0142','3')\nset_inflood_true(all_years,2000,'0142','5')\nset_inflood_true(all_years,2000,'0065','7')\nset_inflood_true(all_years,2000,'0065','4')\nset_inflood_true(all_years,2000,'0099','1')\nset_inflood_true(all_years,2000,'0116','3')\nset_inflood_true(all_years,2000,'004102','2')\nset_inflood_true(all_years,2000,'0207','5')\nset_inflood_true(all_years,2000,'0183','3')\nset_inflood_true(all_years,2000,'0184','2')\nset_inflood_true(all_years,2000,'0142','2')\nset_inflood_true(all_years,2000,'0159','2')\nset_inflood_true(all_years,2000,'0160','7')\nset_inflood_true(all_years,2000,'0186','7')\nset_inflood_true(all_years,2000,'0295','1')\nset_inflood_true(all_years,2000,'0294','4')\nset_inflood_true(all_years,2000,'0183','4')\nset_inflood_true(all_years,2000,'0293','2')\n\nset_inflood_true(all_years,2010,'032900','1')\nset_inflood_true(all_years,2015,'032900','1')\nset_inflood_true(all_years,2018,'032900','1')\nset_inflood_true(all_years,2010,'033690','1')\nset_inflood_true(all_years,2015,'033690','1')\nset_inflood_true(all_years,2018,'033690','1')\nset_inflood_true(all_years,2010,'036900','1')\nset_inflood_true(all_years,2015,'036900','1')\nset_inflood_true(all_years,2018,'036900','1')\nset_inflood_true(all_years,2010,'036900','2')\nset_inflood_true(all_years,2015,'036900','2')\nset_inflood_true(all_years,2018,'036900','2')\nset_inflood_true(all_years,2010,'980000','1')\nset_inflood_true(all_years,2015,'980000','1')\nset_inflood_true(all_years,2018,'980000','1')\n\nset_inflood_true(all_years,2021,'989100','2')\nset_inflood_true(all_years,2021,'980701','2')\nset_inflood_true(all_years,2021,'980901','4')\nset_inflood_true(all_years,2021,'036902','4')\nset_inflood_true(all_years,2021,'037500','1')\nset_inflood_true(all_years,2021,'014201','2')\nset_inflood_true(all_years,2021,'980903','1')\nset_inflood_true(all_years,2021,'003300','2')\nset_inflood_true(all_years,2021,'003300','2')\nset_inflood_true(all_years,2021,'035100','2')\n\nset_inflood_false(all_years,2021,'035900','2')\nset_inflood_false(all_years,2021,'036000','3')\nset_inflood_false(all_years,2021,'980300','1')\n\n\nset_inflood_false(all_years,2000,'0361','1')\nset_inflood_false(all_years,2000,'0055','1')\nset_inflood_false(all_years,2000,'0044','1')\n\nset_inflood_false(all_years,2010,'035900','2')\nset_inflood_false(all_years,2015,'035900','2')\nset_inflood_false(all_years,2018,'035900','2')"
  },
  {
    "objectID": "analysis/1-race-analysis.html#geographic-breakdown",
    "href": "analysis/1-race-analysis.html#geographic-breakdown",
    "title": "Census Analysis",
    "section": "Geographic Breakdown",
    "text": "Geographic Breakdown\nNext, we analyze the patterns by region to see if there are differences in the trends across the different geographic areas of Philadelphia. Data on planning districts is downloaded from open data Philadelphia, and the planning districts are grouped into seven larger geographic areas: River Wards, Northeast, Northwest, Center City, West & North, South, and Southwest.\nThe census block groups are then assigned to the geographic area they are situated in and a new column which contains the name of the geographic area is added to the flood tracts dataframe.\n\n\nCode\narea = {'River Wards':'River Wards',\n'North Delaware':'Northeast',\n'Lower Far Northeast':'Northeast',\n'Central':'Center City',\n'University Southwest':'West & North',\n'Upper Northwest':'Northwest',\n'Upper North':'Northwest',\n'South':'South',\n'North':'West & North',\n'Lower Northwest':'Northwest',\n'Lower South':'South',\n'Lower Northeast':'Northeast',\n'Central Northeast':'Northeast',\n'West':'West & North',\n'Upper Far Northeast':'Northeast',\n'Lower Southwest':'Southwest',\n'West Park':'West & North',\n'Lower North':'West & North'\n}\n\n\n\n\nCode\nplanning_districts = gpd.read_file('https://opendata.arcgis.com/datasets/0960ea0f38f44146bb562f2b212075aa_0.geojson').to_crs(6565)\n\nplanning_districts['region'] = planning_districts['DIST_NAME'].map(area)\n\n\n\n\nCode\npoints_flood = gpd.GeoDataFrame(geometry=flood_tracts['geometry'].centroid)\n\npoints_flood = points_flood.sjoin(planning_districts,how='inner')\npoints_flood = points_flood[['region']]\n\nflood_tracts_area = flood_tracts.merge(points_flood,left_index=True, right_index=True)\n\n\nThe map on the left below shows how the planning districts have been divided into geographic areas which are used for the analysis. The map on the right shows the census block groups that are located adjacent to the flood plain colored according to the geographic area they are located in.\n\n\nCode\nplot1 = planning_districts.hvplot(\n    c=\"region\",\n    frame_width=200,\n    frame_height=200,\n    geo=True,\n    crs=6565,\n    hover_cols=[\"DIST_NAME\"]\n)\n\nplot2 = flood_tracts_area.hvplot(\n    c=\"region\",\n    frame_width=200,\n    frame_height=200,\n    geo=True,\n    crs=6565\n)\n\nplot1 + plot2\n\n\n\n\n\n\n  \n\n\n\n\nThe chart below shows the trend in the population living in census block groups located near the floodplain by region of the city. Some notable patterns include a large expansion in the population in center city living in census block groups located near the flood hazard zone. Between 2015 and 2021 there was also increase in the population living in census block groups located near the flood hazard zone in Northeast, Northwest, and South Philadelphia.\n\n\nCode\nflood_tracts_melt = pd.melt(flood_tracts_area,id_vars=['block group','year','region'],\n                            value_vars=['White_Pop','Black_Pop','Asian_Pop','Hispanic_Pop','Other_Pop'],\n                           var_name='Race',value_name='Population')\n                                                       \nalt.Chart(flood_tracts_melt).mark_line(point=True).encode(\n    alt.X('year:N').title('Year'),\n    alt.Y('sum(Population)').title('Total Population'),\n    color='region',\n    tooltip=[\"year\", \"region\", \"sum(Population)\"]\n).properties(\n    width=500,\n    height=300,\n    title='Population Living in Census Block Groups Near Floodplain by Area'\n)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "My name is Richard Barad, and I am student in the Master of Urban Spatial Analytics (MUSA) program at the University of Pennslyvania.\nI prepared this website as part of my final project for MUSA 5500 - Geospatial Analysis in Python. This website was built using Quarto."
  },
  {
    "objectID": "analysis/2-amenity-analysis.html",
    "href": "analysis/2-amenity-analysis.html",
    "title": "Amenity Analysis",
    "section": "",
    "text": "This analysis looks at the number of amenities located within the flood hazard area in the city of Philadelphia. Amenity data is downloaded from Open Street Maps, and I also determine the planning district that each amenity is located in. I present the results using interactive maps created using the geopandas explore() function and charts created using the altair package."
  },
  {
    "objectID": "analysis/2-amenity-analysis.html#data-visualization",
    "href": "analysis/2-amenity-analysis.html#data-visualization",
    "title": "Amenity Analysis",
    "section": "Data Visualization",
    "text": "Data Visualization\nThe chart below shows the percentage of each amenity located in the 100 year flood zone, the 500 year flood zone, and amenities located outside of the flood plain. Pubs, fire stations, and fast food restaurants have the highest percentage of points located in the flood hazard zone. The high percentage of fire stations located in the flood zone is concerning, due to the imortant role this feature plays in emergancy response.\n\n\nCode\ndomain = ['100 YEAR', '500 YEAR', 'Not in Floodplain']\nrange1 = ['blue','lightblue','lightgrey']\n\nalt.Chart(amenities_join).mark_bar().encode(\n    alt.X('amenity').title('Amenity Type'),\n    alt.Y('count(amenity)').title('Percent of Total').stack(\"normalize\"),\n    alt.Color('ZONE').scale(domain=domain, range=range1),\n    tooltip=['amenity','count(amenity)','ZONE']\n).properties(\n    width=400,\n    height=300,\n    title='Percent of Citywide Amenities Located in Areas Vulnerable to Flooding'\n)\n\n\n\n\n\n\n\n\nNext, I create a copy of the amenities dataframe which just includes amenities located in the flood hazard zone.\n\n\nCode\nfilt = amenities_join['ZONE'] != 'Not in Floodplain'\namenities_flood = amenities_join.loc[filt]\n\n\nThe interactive map below shows the location of amenities which are located in the flood hazard zone. The amenities are colored according to the amenity type. Hover over a point to view more information about the amenity.\n\n\nCode\namenities_flood.explore(column='amenity',tiles='CartoDB positron')\n\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nThe chart below shows the number of amenities by amenity type located in the flood hazard area. The color allows for distinguishing between amenities in the 100 year and 500 year flood hazard zones. There are a large number of restaurants and fast food establishments located in flood hazard areas.\n\n\nCode\ndomain1 = ['100 YEAR','500 YEAR']\nrange2 = ['blue','lightblue']\n\nalt.Chart(amenities_flood).mark_bar().encode(\n    alt.X('amenity').title('Amenity Type'),\n    alt.Y('count(amenity)').title('Total'),\n    alt.Color('ZONE').scale(domain=domain1, range=range2),\n    tooltip=['amenity','count(amenity)','ZONE']\n).properties(\n    width=400,\n    height=300,\n    title='Number of Amenities Located in Areas Vulnerable to Flooding'\n)"
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Analysis\nThis section includes three analyses that I have completed as part of this final project. They are:\n\nAn analysis of how the demographic breakdown of the population living in the floodplain, including a breakdown by neighboorhood\nAn analysis of amenities located within the floodplain\nAn analysis of buildings located within the floodplain"
  }
]